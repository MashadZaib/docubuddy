# ğŸ“„ Local PDF Chatbot with LangChain & Streamlit

A lightweight, local Retrieval-Augmented Generation (RAG) chatbot built using [LangChain](https://www.langchain.com/), [Streamlit](https://streamlit.io/), and [Ollama](https://ollama.com/) â€” allowing you to upload PDFs and chat with them using an open-source model like `mistral`.

---

## ğŸš€ Features

- ğŸ“ Upload **any PDF**
- ğŸ¤– Ask **natural language questions** about its content
- ğŸ§  Powered by **LangChain ConversationalRetrievalChain**
- ğŸ” Answers with **context + source documents**
- ğŸ’¬ Keeps track of conversation **within session**
- ğŸ’» **Runs fully locally** â€” no OpenAI key needed
- ğŸ§© Uses **Ollama** + `mistral` model or your own

---

## ğŸ›  Requirements

- Python 3.9 or above
- [Ollama](https://ollama.com/) installed locally (must have the `mistral` model pulled)
- Recommended: Chrome or modern browser

---

## ğŸ“¦ Installation

### 1. Clone the repo or copy files
```bash
git clone https://github.com/yourname/local-pdf-chatbot
cd rag-pdf-chatbot
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
ollama pull mistral
streamlit run app.py
.
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt     # All required dependencies
â””â”€â”€ README.md            # You're reading it!
git commit -m "all commit"
